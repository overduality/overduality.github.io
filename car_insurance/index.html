<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Car Insurance Claim Prediction & Risk Quantification</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Libre+Baskerville:wght@400;700&family=IBM+Plex+Sans:wght@400;500;600&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    :root {
      --text: #1a1a1a;
      --text-light: #666;
      --border: #e0e0e0;
      --bg-light: #fafafa;
      --accent: #0891b2;
    }

    html {
      scroll-behavior: smooth;
    }

    body {
      font-family: 'IBM Plex Sans', sans-serif;
      color: var(--text);
      background: #ffffff;
      line-height: 1.75;
      font-size: 17px;
    }

    .sidebar {
      position: fixed;
      left: 0;
      top: 0;
      bottom: 0;
      width: 260px;
      background: var(--bg-light);
      border-right: 1px solid var(--border);
      padding: 48px 24px;
      overflow-y: auto;
      z-index: 100;
    }

    .sidebar-title {
      font-family: 'Libre Baskerville', serif;
      font-size: 20px;
      font-weight: 700;
      margin-bottom: 24px;
      color: var(--text);
      line-height: 1.3;
    }

    .back-button {
      display: flex;
      align-items: center;
      gap: 8px;
      padding: 10px 16px;
      background: var(--bg-light);
      border: 1px solid var(--border);
      border-radius: 6px;
      text-decoration: none;
      color: var(--text);
      font-size: 14px;
      font-weight: 500;
      margin-bottom: 24px;
      transition: all 0.2s ease;
    }

    .back-button:hover {
      background: var(--accent);
      color: white;
      border-color: var(--accent);
    }

    .github-link {
      display: flex;
      align-items: center;
      gap: 8px;
      padding: 10px 16px;
      background: #24292e;
      border: 1px solid #24292e;
      border-radius: 6px;
      text-decoration: none;
      color: white;
      font-size: 14px;
      font-weight: 500;
      margin-bottom: 24px;
      transition: all 0.2s ease;
    }

    .github-link:hover {
      background: #1a1f24;
      border-color: #1a1f24;
    }

    .sidebar-nav {
      list-style: none;
      padding-left: 0rem;
    }

    .sidebar-nav li {
      margin-bottom: 4px;
    }

    .sidebar-nav a {
      display: block;
      padding: 10px 16px;
      color: var(--text-light);
      text-decoration: none;
      font-size: 15px;
      border-radius: 6px;
      transition: all 0.2s ease;
      font-weight: 500;
    }

    .sidebar-nav a:hover {
      background: rgba(8, 145, 178, 0.08);
      color: var(--accent);
    }

    .sidebar-nav a.active {
      background: rgba(8, 145, 178, 0.12);
      color: var(--accent);
      font-weight: 600;
    }

    .main {
      margin-left: 260px;
      padding: 80px 100px 120px 100px;
      max-width: 1100px;
    }

    h1 {
      font-family: 'Libre Baskerville', serif;
      font-size: 48px;
      line-height: 1.2;
      font-weight: 700;
      margin-bottom: 20px;
      letter-spacing: -0.02em;
    }

    h2 {
      font-family: 'Libre Baskerville', serif;
      font-size: 36px;
      font-weight: 700;
      margin: 80px 0 28px 0;
      letter-spacing: -0.01em;
      scroll-margin-top: 40px;
    }

    h3 {
      font-size: 24px;
      font-weight: 600;
      margin: 48px 0 20px 0;
      color: var(--text);
    }

    .lead {
      font-size: 21px;
      color: var(--text-light);
      margin-bottom: 48px;
      line-height: 1.6;
    }

    p {
      margin-bottom: 20px;
    }

    strong {
      font-weight: 600;
      color: var(--text);
    }

    section {
      opacity: 0;
      transform: translateY(30px);
      transition: opacity 0.6s ease, transform 0.6s ease;
    }

    section.visible {
      opacity: 1;
      transform: translateY(0);
    }

    .result-box {
      background: linear-gradient(135deg, #ecfeff 0%, #cffafe 100%);
      border: 1px solid var(--border);
      border-left: 4px solid var(--accent);
      padding: 32px;
      margin: 40px 0;
      border-radius: 8px;
    }

    .result-box h3 {
      margin-top: 0;
      margin-bottom: 16px;
      font-size: 22px;
    }

    .stats-grid {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 20px;
      margin: 48px 0;
    }

    .stat-card {
      background: var(--bg-light);
      border: 1px solid var(--border);
      padding: 28px 24px;
      text-align: center;
      border-radius: 8px;
      transition: transform 0.3s ease, box-shadow 0.3s ease;
    }

    .stat-card:hover {
      transform: translateY(-4px);
      box-shadow: 0 12px 24px rgba(0,0,0,0.06);
    }

    .stat-value {
      display: block;
      font-size: 36px;
      font-weight: 700;
      color: var(--accent);
      margin-bottom: 8px;
      font-family: 'JetBrains Mono', monospace;
    }

    .stat-label {
      font-size: 14px;
      color: var(--text-light);
      font-weight: 500;
    }

    ul, ol {
      margin: 24px 0;
      padding-left: 28px;
    }

    li {
      margin-bottom: 12px;
      color: var(--text);
    }

    li::marker {
      color: var(--accent);
    }

    code {
      font-family: 'JetBrains Mono', monospace;
      font-size: 14px;
      background: #f5f5f5;
      padding: 3px 8px;
      border-radius: 4px;
      border: 1px solid var(--border);
    }

    pre {
      font-family: 'JetBrains Mono', monospace;
      font-size: 14px;
      background: #f5f5f5;
      border: 1px solid var(--border);
      border-radius: 8px;
      padding: 24px;
      margin: 32px 0;
      overflow-x: auto;
      line-height: 1.6;
    }

    pre code {
      background: none;
      padding: 0;
      border: none;
    }

    .viz-container {
      background: var(--transparent);
      border-radius: 8px;
      padding: 20px;
      text-align: center;
      margin: 40px 0;
      position: relative;
      overflow: hidden;
    }

    .viz-image {
      max-width: 100%;
      height: auto;
      display: block;
      margin: 0 auto;
      border-radius: 4px;
      box-shadow: 0 4px 12px rgba(0,0,0,0.08);
      transition: transform 0.3s ease;
    }

    .viz-image:hover {
      transform: scale(1.02);
    }

    table {
      width: 100%;
      border-collapse: collapse;
      margin: 40px 0;
      font-size: 15px;
      border: 1px solid var(--border);
      border-radius: 8px;
      overflow: hidden;
    }

    th, td {
      text-align: left;
      padding: 16px 20px;
      border-bottom: 1px solid var(--border);
    }

    th {
      font-weight: 600;
      background: var(--bg-light);
      font-family: 'JetBrains Mono', monospace;
      font-size: 13px;
      text-transform: uppercase;
      letter-spacing: 0.05em;
      color: var(--text);
    }

    tbody tr:hover {
      background: var(--bg-light);
    }

    .highlight {
      background: #ecfeff;
      font-weight: 600;
    }

    .callout {
      background: #fefce8;
      border-left: 4px solid #facc15;
      padding: 24px 28px;
      margin: 40px 0;
      border-radius: 8px;
    }

    .callout-title {
      font-weight: 600;
      margin-bottom: 12px;
      font-size: 18px;
      color: var(--text);
    }

    .tech-tags {
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      margin: 32px 0;
    }

    .tech-tag {
      font-family: 'JetBrains Mono', monospace;
      font-size: 13px;
      padding: 8px 16px;
      background: var(--bg-light);
      border: 1px solid var(--border);
      border-radius: 6px;
      font-weight: 500;
      transition: all 0.2s ease;
    }

    .tech-tag:hover {
      background: rgba(8, 145, 178, 0.08);
      border-color: var(--accent);
      color: var(--accent);
    }

    .tech-stack-images {
      margin-top: 40px;
      padding-top: 32px;
      border-top: 1px solid var(--border);
    }

    .tech-stack-title {
      font-size: 14px;
      font-weight: 600;
      color: var(--text-light);
      text-transform: uppercase;
      letter-spacing: 0.05em;
      margin-bottom: 20px;
      text-align: center;
    }

    .tech-images-grid {
      display: grid;
      grid-template-columns: repeat(4, 1fr);
      gap: 20px;
    }

    .tech-image-card {
      background: white;
      border-radius: 12px;
      padding: 0px;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: all 0.3s ease;
      aspect-ratio: 1 / 1;
    }

    .tech-image-card:hover {
      border-color: var(--accent);
      box-shadow: 0 4px 16px rgba(8, 145, 178, 0.15);
      transform: translateY(-4px);
    }

    .tech-image-card img {
      max-width: 80%;
      max-height: 80%;
      object-fit: contain;
      filter: grayscale(100%);
      opacity: 0.7;
      transition: all 0.3s ease;
    }

    .tech-image-card:hover img {
      filter: grayscale(0%);
      opacity: 1;
      transform: scale(1.1);
    }

    .divider {
      height: 1px;
      background: var(--border);
      margin: 80px 0;
    }

    @media (max-width: 1024px) {
      .sidebar {
        display: none;
      }

      .main {
        margin-left: 0;
        padding: 48px 32px 80px 32px;
      }

      h1 {
        font-size: 36px;
      }

      h2 {
        font-size: 28px;
        margin: 60px 0 24px 0;
      }

      .stats-grid {
        grid-template-columns: 1fr;
      }
      
      .viz-container {
        padding: 15px;
      }

      .tech-images-grid {
        grid-template-columns: repeat(2, 1fr);
      }
    }
  </style>
</head>
<body>

  <aside class="sidebar">
    <a href="/" class="back-button">
      <svg width="16" height="16" viewBox="0 0 16 16" fill="currentColor">
        <path d="M8 0L6.59 1.41L12.17 7H0v2h12.17l-5.58 5.59L8 16l8-8z" transform="rotate(180 8 8)"/>
      </svg>
      Back to Projects
    </a>
    <div class="sidebar-title">Car Insurance Claim Prediction</div>
    <a href="https://github.com/overduality/insurance-claim-prediction" target="_blank" rel="noopener noreferrer" class="github-link">
      <svg width="16" height="16" viewBox="0 0 16 16" fill="currentColor">
        <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/>
      </svg>
      View on GitHub
    </a>
    <nav>
      <ul class="sidebar-nav">
        <li><a href="#overview" class="active">Overview</a></li>
        <li><a href="#problem">Problem</a></li>
        <li><a href="#methodology">Data Engineering</a></li>
        <li><a href="#eda">Exploratory Analysis</a></li>
        <li><a href="#modeling">Model Development</a></li>
        <li><a href="#results">Results</a></li>
        <li><a href="#risk-quantification">Risk Quantification</a></li>
        <li><a href="#impact">Business Impact</a></li>
      </ul>
    </nav>
  </aside>

  <main class="main">

    <section id="overview" class="visible">
      <h1>Car Insurance Claim Prediction & Risk Quantification</h1>
      <p class="lead">
        A two-stage machine learning system combining CatBoost classification with SGD regression to identify high-risk policyholders. The model concentrates 47% of total claim losses in the top 10% risk segment, enabling data-driven premium pricing.
      </p>

      <div class="stats-grid">
        <div class="stat-card">
          <span class="stat-value">47%</span>
          <span class="stat-label">Loss in Top 10%</span>
        </div>
        <div class="stat-card">
          <span class="stat-value">76%</span>
          <span class="stat-label">Claim Recall</span>
        </div>
        <div class="stat-card">
          <span class="stat-value">$5.7K</span>
          <span class="stat-label">Avg Claim Severity</span>
        </div>
      </div>

      <div class="result-box">
        <h3>What This System Delivers</h3>
        <p>
          A dual-model pipeline that quantifies expected loss per policyholder: CatBoost classifier (83% ROC-AUC) predicts claim probability with optimized threshold (0.2922) prioritizing recall (76%) over precision (55%), while SGD regressor estimates claim severity. The combined system successfully concentrates 47.03% of total losses in the top 10% risk segment, proving the model can separate high-risk from low-risk drivers for actuarial pricing.
        </p>
      </div>

      <p><strong>The Problem:</strong> Insurance companies lose money when premiums don't reflect actual risk. Flat-rate pricing subsidizes high-risk drivers at the expense of safe drivers, leading to adverse selection. Traditional actuarial models miss complex feature interactions that predict claims.</p>

      <p><strong>The Solution:</strong> Machine learning models learn non-linear relationships between driver characteristics and claim outcomes, then quantify expected financial loss per policy, enabling risk-based premium adjustments that improve profitability while retaining safe drivers.</p>

      <div class="tech-tags">
        <span class="tech-tag">Python</span>
        <span class="tech-tag">Scikit-learn</span>
        <span class="tech-tag">CatBoost</span>
        <span class="tech-tag">Feature Engineering</span>
        <span class="tech-tag">Imbalanced Learning</span>
        <span class="tech-tag">Pipeline Automation</span>
      </div>

      <div class="tech-stack-images">
        <div class="tech-images-grid">
          <div class="tech-image-card">
            <img src="https://www.python.org/static/community_logos/python-logo-generic.svg" alt="Python Logo">
          </div>
          <div class="tech-image-card">
            <img src="https://upload.wikimedia.org/wikipedia/commons/0/05/Scikit_learn_logo_small.svg" alt="Scikit-learn Logo">
          </div>
          <div class="tech-image-card">
            <img src="https://upload.wikimedia.org/wikipedia/commons/c/cc/CatBoostLogo.png" alt="CatBoost Logo">
          </div>
          <div class="tech-image-card">
            <img src="https://numpy.org/images/logo.svg" alt="NumPy Logo">
          </div>
        </div>
      </div>
    </section>

    <div class="divider"></div>

    <section id="problem">
      <h2>Problem Statement</h2>
      
      <p>Auto insurance requires solving two interdependent prediction problems:</p>

      <h3>Challenge 1: Claim Occurrence (Classification)</h3>
      <ul>
        <li><strong>Class Imbalance:</strong> Only 26.48% of policies result in claims (2.78:1 ratio), standard models overfit to the majority class</li>
        <li><strong>Binary Outcome:</strong> Will this driver file a claim? (Yes/No)</li>
        <li><strong>Business Trade-off:</strong> False negatives (missed claims) cost more than false positives (over-cautious reserves)</li>
      </ul>

      <h3>Challenge 2: Claim Severity (Regression)</h3>
      <ul>
        <li><strong>Extreme Skew:</strong> Claims range from $500 (minor dent) to $50,000+ (total loss)</li>
        <li><strong>Conditional Prediction:</strong> Only train on policyholders who actually claimed</li>
        <li><strong>Outlier Volatility:</strong> Single catastrophic claim can skew predictions, requires robust regression</li>
      </ul>

      <h3>Business Requirements</h3>
      <ol>
        <li>Identify top 10% riskiest drivers for premium surcharges</li>
        <li>Quantify expected loss in dollars for reserve planning</li>
        <li>Maintain regulatory compliance and fairness</li>
        <li>Provide interpretable features for actuarial review</li>
      </ol>
    </section>

    <div class="divider"></div>

    <section id="methodology">
      <h2>Data Engineering & Feature Engineering</h2>

      <h3>Dataset Overview</h3>
      <p>Real-world car insurance dataset with <strong>10,301 policies</strong> (after deduplication) containing 26 features plus 2 target variables:</p>
      
      <p><strong>Demographics (6):</strong> age, gender, marital_status, education, occupation, single_parent</p>
      <p><strong>Financial (3):</strong> income, home_value, vehicle_value</p>
      <p><strong>Vehicle (4):</strong> vehicle_type, vehicle_age, red_vehicle, type_of_use</p>
      <p><strong>Behavioral (9):</strong> num_young_drivers, num_of_children, years_job_held_for, commute_dist, policy_tenure, 5_year_total_claims_value, 5_year_num_of_claims, license_points, licence_revoked</p>
      <p><strong>Location (1):</strong> address_type (urban/rural)</p>
      <p><strong>Targets (2):</strong> is_claim (binary), new_claim_value (continuous)</p>

      <h3>Critical Data Cleaning Decisions</h3>

      <p><strong>1. Missing Value Strategy</strong></p>
      <pre><code># Numerical: KNN Imputation (k=2)
# Preserves local correlations (e.g., income ↔ home value)
knn_imputer = KNNImputer(n_neighbors=2)
imputed_num = knn_imputer.fit_transform(numerical_features)

# Categorical: Mode Imputation
# Prevents introducing noise in one-hot encoding
simple_imputer = SimpleImputer(strategy='most_frequent')
imputed_cat = simple_imputer.fit_transform(categorical_features)</code></pre>

      <p><strong>Why KNN for numerics?</strong> KNN preserves feature correlations (e.g., high-income drivers typically have higher home values), providing more realistic imputation than mean/median.</p>

      <p><strong>2. Encoding Strategy</strong></p>
      <table>
        <thead>
          <tr>
            <th>Feature</th>
            <th>Encoding</th>
            <th>Rationale</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>highest_education</td>
            <td>Ordinal</td>
            <td>Clear ranking: &lt;High School &lt; Bachelors &lt; Masters &lt; PhD</td>
          </tr>
          <tr>
            <td>gender, married, single_parent, type_of_use, licence_revoked, address_type</td>
            <td>Binary (Ordinal with 2 categories)</td>
            <td>Two categories only</td>
          </tr>
          <tr>
            <td>occupation, vehicle_type</td>
            <td>One-Hot (drop first)</td>
            <td>No inherent order; 8 and 6 categories respectively</td>
          </tr>
        </tbody>
      </table>

      <div class="callout">
        <div class="callout-title">Multicollinearity Check</div>
        <p>Initial one-hot encoding produced VIF &gt; 100 for occupation/vehicle type (perfect multicollinearity). Solution: Drop reference categories ("Blue Collar", "Minivan") to break dependency. Post-correction VIF &lt; 10 for all features.</p>
      </div>

      <p><strong>3. Distribution Correction</strong></p>
      <p>Six features exhibited severe right skew, requiring square root transformation:</p>

      <pre><code># Square root transformation (gentler than log for moderate skew)
skewed_features = ['income', 'value_of_home', 'commute_dist', 
                   'vehicle_value', 'policy_tenure', 'license_points']

for feature in skewed_features:
    X[feature] = np.sqrt(X[feature])</code></pre>

      <p><strong>Result:</strong> Improved model convergence and reduced influence of extreme values in gradient-based algorithms.</p>
    </section>

    <div class="divider"></div>

    <section id="eda">
      <h2>Exploratory Data Analysis</h2>

      <h3>Correlation Analysis</h3>
      <p>Correlation matrix revealed key predictive features for claim occurrence:</p>
      <ul>
        <li><strong>5_year_num_of_claims:</strong> Strongest predictor (past behavior predicts future)</li>
        <li><strong>license_points:</strong> High correlation with risky driving</li>
        <li><strong>licence_revoked:</strong> Clear indicator of high-risk driver</li>
        <li><strong>policy_tenure:</strong> Negative correlation (loyal customers = safer)</li>
      </ul>

      <div class="viz-container">
        <img src="./images/corr_matrix.png" alt="Correlation Matrix of Features" class="viz-image">
      </div>

      <h3>Feature Distribution Analysis</h3>
      <p>Examined distributions of all numerical features before and after square root transformation:</p>

      <div class="viz-container">
        <img src="./images/hist.png" alt="Feature Distribution Before Transformation" class="viz-image">
      </div>

      <div class="viz-container">
        <img src="./images/hist_skewed.png" alt="Feature Distribution After Transformation" class="viz-image">
      </div>

      <h3>Claim Value Distribution</h3>
      <p>Analysis of claim severity showed extreme right skew with long tail extending to $50K+, justifying log-transformation for regression modeling.</p>

      <div class="viz-container">
        <img src="./images/new_claim_value.png" alt="Distribution of Claim Values" class="viz-image">
      </div>
    </section>

    <div class="divider"></div>

    <section id="modeling">
      <h2>Model Development</h2>

      <h3>Phase 1: Claim Occurrence Model (Classification)</h3>

      <p><strong>Model Selection via 10-Fold Cross-Validation:</strong></p>

      <div class="viz-container">
        <img src="./images/cv_diff_claf.png" alt="Comparison of Classification Models" class="viz-image">
      </div>

      <table>
        <thead>
          <tr>
            <th>Model</th>
            <th>CV Accuracy</th>
            <th>Std Dev</th>
          </tr>
        </thead>
        <tbody>
          <tr class="highlight">
            <td>CatBoost</td>
            <td>79.44%</td>
            <td>±1.80%</td>
          </tr>
          <tr>
            <td>Gradient Boost</td>
            <td>~79.5%</td>
            <td>±1.7%</td>
          </tr>
          <tr>
            <td>XGBoost</td>
            <td>~78.8%</td>
            <td>±1.9%</td>
          </tr>
          <tr>
            <td>Random Forest</td>
            <td>~78.7%</td>
            <td>±2.1%</td>
          </tr>
        </tbody>
      </table>

      <p><strong>CatBoost selected due to:</strong></p>
      <ul>
        <li>Competitive accuracy with excellent stability (low variance)</li>
        <li>Built-in categorical handling (no manual encoding needed for production)</li>
        <li>Ordered boosting reduces overfitting vs traditional gradient boosting</li>
      </ul>

      <h3>Hyperparameter Optimization</h3>

      <pre><code># RandomizedSearchCV with 500 iterations
param_grid = {
    'n_estimators': randint(150, 350),         
    'learning_rate': uniform(0.08, 0.17),        
    'max_depth': randint(4, 9),                 
    'subsample': uniform(0.7, 0.3),            
    'colsample_bylevel': uniform(0.7, 0.3),     
    'min_data_in_leaf': randint(10, 35),       
    'reg_lambda': randint(5, 60),                
    'scale_pos_weight': [1, 1.6, 2.78],        # Address 26% minority class
    'bagging_temperature': uniform(0.3, 0.7),    
    'random_strength': [0, 1, 2]                
}

# Optimize for PR-AUC (better for imbalanced data than accuracy)
random_search = RandomizedSearchCV(
    estimator=CatBoostClassifier(),
    param_distributions=param_grid,
    n_iter=500,
    cv=5,
    scoring='average_precision'
)

best_model = random_search.fit(X_train, y_train).best_estimator_</code></pre>

      <p><strong>Key finding:</strong> <code>scale_pos_weight=2.78</code> (inverse of class ratio) significantly improved recall on the minority class (claims).</p>

      <h3>Phase 2: Claim Severity Model (Regression)</h3>

      <p>Trained <strong>only on policyholders who filed claims</strong> (N=2,657 from 10,301 total):</p>

      <div class="viz-container">
        <img src="./images/cv_regressor.png" alt="Comparison of Regression Models" class="viz-image">
      </div>


      <p><strong>For insurance severity with extreme skew, simplicity wins. Linear models avoid chasing outliers that dominate tree-based splits—critical for portfolio-level risk estimation where relative ranking matters more than absolute precision.</p>

      <pre><code># Log-transform target to handle skew
wrapped_sgd = TransformedTargetRegressor(
    regressor=SGDRegressor(random_state=42),
    func=np.log1p,
    inverse_func=np.expm1
)

# Optimized hyperparameters (from RandomizedSearchCV)
best_params = {
    'penalty': 'elasticnet',
    'alpha': 0.005,
    'learning_rate': 'invscaling',
    'eta0': 0.08
}</code></pre>
    </section>

    <div class="divider"></div>

    <section id="results">
      <h2>Model Performance</h2>

      <h3>Classification Results (Claim Occurrence)</h3>

      <div class="result-box">
        <h3>Test Set Performance (Optimized Threshold: 0.2922)</h3>
        <ul>
          <li><strong>ROC-AUC:</strong> 0.8289 (good discrimination ability)</li>
          <li><strong>Precision:</strong> 55% (accepts false positives to maximize claim detection)</li>
          <li><strong>Recall:</strong> 76% (catches 76% of all actual claimants)</li>
          <li><strong>F1 Score:</strong> 0.64 (maximized via threshold tuning)</li>
          <li><strong>Overall Accuracy:</strong> 76%</li>
        </ul>
      </div>

      <p><strong>Threshold Optimization Strategy:</strong> Default 0.5 threshold produced poor recall (45%), missing 55% of claims. Precision-recall curve analysis identified optimal threshold of <strong>0.2922</strong>, which maximizes F1 score at 0.6358 by prioritizing recall (76%) over precision (55%).</p>

      <div class="callout">
        <div class="callout-title">Business Justification for Low Threshold</div>
        <p>In insurance, <strong>missing a claim costs far more than being over-cautious.</strong> A false negative means unexpected payouts and underpriced risk, while a false positive merely overestimates reserves. The 0.2922 threshold accepts 45% false positive rate to achieve 76% claim detection, a worthwhile trade-off for loss prevention.</p>
      </div>

      <h3>Confusion Matrix Analysis</h3>

      <div class="viz-container">
        <img src="./images/conf_cat_thres.png" alt="Confusion Matrix at Optimal Threshold" class="viz-image">
      </div>

      <table>
        <thead>
          <tr>
            <th></th>
            <th>Predicted: No Claim</th>
            <th>Predicted: Claim</th>
            <th>Total</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>Actual: No Claim</strong></td>
            <td>1,147 (TN)</td>
            <td>350 (FP)</td>
            <td>1,497</td>
          </tr>
          <tr>
            <td><strong>Actual: Claim</strong></td>
            <td>138 (FN)</td>
            <td>426 (TP)</td>
            <td>564</td>
          </tr>
        </tbody>
      </table>

      <p><strong>Business interpretation:</strong></p>
      <ul>
        <li><strong>350 false positives:</strong> Overestimation of reserves by ~$1.7M (manageable with conservative actuarial practices)</li>
        <li><strong>138 false negatives:</strong> Approximately $770K in unexpected payouts, reduced from 310 FN at default threshold</li>
        <li><strong>Trade-off accepted:</strong> Increased false positives are acceptable given substantial reduction in catastrophic missed claims</li>
      </ul>

      <h3>Regression Results (Claim Severity)</h3>

      <ul>
        <li><strong>Test RMSE:</strong> $8,353 (actual performance on held-out test set)</li>
        <li><strong>Test MAE:</strong> $2,968 (average prediction error per claim)</li>
      </ul>

      <div class="callout">
        <div class="callout-title">Why High RMSE?</div>
        <p>Claim amounts are inherently volatile, identical drivers can have $1K (fender bender) vs $40K (rollover) accidents due to random factors like weather, collision angle, and vehicle damage mechanics. The model predicts <em>expected value</em> for portfolio-level risk aggregation, not individual precision. RMSE of $8,353 is acceptable for actuarial reserve planning where we aggregate thousands of policies.</p>
      </div>

      <h3>Threshold Comparison</h3>
      <table>
        <thead>
          <tr>
            <th>Threshold</th>
            <th>Precision</th>
            <th>Recall</th>
            <th>F1</th>
            <th>Use Case</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>0.5 (Default)</td>
            <td>70%</td>
            <td>45%</td>
            <td>0.55</td>
            <td>Conservative (avoids false alarms)</td>
          </tr>
          <tr class="highlight">
            <td>0.2922 (Optimal)</td>
            <td>55%</td>
            <td>76%</td>
            <td>0.64</td>
            <td><strong>Production:</strong> Maximizes claim detection</td>
          </tr>
        </tbody>
      </table>
    </section>

    <div class="divider"></div>

    <section id="risk-quantification">
      <h2>Risk Quantification & Decile Analysis</h2>

      <h3>Expected Loss Framework</h3>

      <p>The actuarial gold standard: <strong>Expected Loss = P(Claim) × E[Severity | Claim]</strong></p>

      <pre><code># Combine both models
claim_prob = classifier.predict_proba(X_test)[:, 1]
claim_severity = regressor.predict(X_test)

expected_loss = claim_prob * claim_severity

# Segment into risk deciles
risk_deciles = pd.qcut(expected_loss, 10, labels=range(10, 0, -1))</code></pre>

      <h3>Decile Performance Analysis</h3>

      <div class="viz-container">
        <img src="./images/decile.png" alt="Decile Analysis Showing Percentage of Total Loss by Risk Segment" class="viz-image">
      </div>

      <table>
        <thead>
          <tr>
            <th>Risk Decile</th>
            <th>Policy Count</th>
            <th>Actual Loss</th>
            <th>% of Total Loss</th>
          </tr>
        </thead>
        <tbody>
          <tr class="highlight">
            <td>1 (Highest)</td>
            <td>206</td>
            <td>$1,247,000</td>
            <td>47.03%</td>
          </tr>
          <tr>
            <td>2</td>
            <td>206</td>
            <td>$478,000</td>
            <td>17.43%</td>
          </tr>
          <tr>
            <td>3</td>
            <td>206</td>
            <td>$312,000</td>
            <td>11.38%</td>
          </tr>
          <tr>
            <td>4-7 (Mid)</td>
            <td>824</td>
            <td>$543,000</td>
            <td>19.81%</td>
          </tr>
          <tr>
            <td>8-10 (Low)</td>
            <td>618</td>
            <td>$162,000</td>
            <td>5.90%</td>
          </tr>
        </tbody>
      </table>

      <div class="result-box">
        <h3>Key Business Insights</h3>
        <ul>
          <li><strong>Extreme Risk Concentration:</strong> Top 10% of policyholders (206 drivers) account for 47.03% of total dollar payouts ($1.25M of $2.65M total)</li>
          <li><strong>Top 20% Dominance:</strong> Top two deciles (412 drivers) represent 64.46% of all losses, enabling targeted premium adjustments</li>
          <li><strong>Safe Driver Subsidy:</strong> Bottom 30% (618 drivers) contribute only 5.9% of losses, currently overpaying under flat pricing</li>
          <li><strong>Model Validation:</strong> This extreme lift curve proves the model successfully separates expensive drivers from safe ones, essential for risk-based pricing</li>
        </ul>
      </div>

      <p><strong>Actuarial Application:</strong> The 47% concentration enables precise pricing strategies:</p>
      <ul>
        <li>Apply 30-40% premium surcharge to top decile (or decline coverage for ultra-high-risk)</li>
        <li>Offer 10-15% discount to bottom 3 deciles to prevent churn to competitors</li>
        <li>Standard pricing for middle deciles (40-70th percentile)</li>
        <li>Result: Simulated revenue-neutral adjustment assuming static customer behavior, real-world elasticity requires validation</li>
      </ul>
    </section>

    <div class="divider"></div>

    <section id="impact">
      <h2>Business Impact & Deployment</h2>

      <h3>Financial Impact Simulation</h3>

      <p>Assuming portfolio of 100,000 policies with $800 average premium:</p>

      <table>
        <thead>
          <tr>
            <th>Scenario</th>
            <th>Annual Premium Revenue</th>
            <th>Expected Payouts</th>
            <th>Profit Margin</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Flat Pricing (Current)</td>
            <td>$80,000,000</td>
            <td>$58,000,000</td>
            <td>27.5%</td>
          </tr>
          <tr class="highlight">
            <td>Risk-Based Pricing</td>
            <td>$80,000,000</td>
            <td>$52,000,000</td>
            <td>35.0%</td>
          </tr>
        </tbody>
      </table>

      <p><strong>Result:</strong> Hypothetical simulation suggests potential for 5-7% loss ratio improvement with risk-based pricing. Actual impact requires 6-month A/B testing to account for customer churn elasticity and competitor responses</p>
      <ul>
        <li>Surcharging high-risk drivers (reduces adverse selection when they leave)</li>
        <li>Discounting low-risk drivers (prevents churn to competitors)</li>
        <li>Declining ultra-high-risk applicants (top 2% with expected loss &gt; 2× premium)</li>
      </ul>

      <h3>Production Deployment Strategy</h3>

      <ol>
        <li><strong>Pipeline Automation:</strong> Scikit-learn pipeline handles all preprocessing (imputation, encoding, scaling) for consistent train/inference</li>
        <li><strong>API Integration:</strong> REST endpoint accepts policy application JSON, returns risk score + expected loss in &lt;200ms</li>
        <li><strong>A/B Testing:</strong> Roll out to 10% of new policies, compare loss ratios vs control group over 6 months</li>
        <li><strong>Monitoring:</strong> Track feature drift (e.g., inflation affecting vehicle values), retrain quarterly</li>
      </ol>

      <h3>Custom Pipeline Architecture</h3>

      <pre><code># Custom transformers for production pipeline
class ColumnDropper(BaseEstimator, TransformerMixin):
    def __init__(self, columns_to_drop):
        self.columns_to_drop = columns_to_drop
    
    def transform(self, X):
        return X.drop(columns=self.columns_to_drop)

class SqrtTransformer(BaseEstimator, TransformerMixin):
    def __init__(self, columns_to_transform):
        self.columns_to_transform = columns_to_transform
    
    def transform(self, X):
        X[self.columns_to_transform] = np.sqrt(X[self.columns_to_transform])
        return X

# Complete preprocessing pipeline
preprocess_pipeline = ColumnTransformer([
    ('drop_features', ColumnDropper(['red_vehicle']), ['red_vehicle']),
    ('num', Pipeline([
        ('knn_imputer', KNNImputer(n_neighbors=2)),
        ('sqrt', SqrtTransformer(skewed_features)),
        ('scaler', StandardScaler())
    ]), numerical_cols),
    ('cat_ord', Pipeline([
        ('simple_imputer', SimpleImputer(strategy='most_frequent')),
        ('ordinal_encoder', OrdinalEncoder(categories=education_rank))
    ]), cat_cols_ord),
    ('cat_bin', Pipeline([
        ('simple_imputer', SimpleImputer(strategy='most_frequent')),
        ('bin_encoder', OrdinalEncoder())
    ]), cat_cols_binary),
    ('cat_one_hot', Pipeline([
        ('simple_imputer', SimpleImputer(strategy='most_frequent')),
        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore', 
                                         sparse_output=False, drop='first'))
    ]), cat_cols_one_hot)
])</code></pre>

      <h3>Regulatory Compliance</h3>

      <ul>
        <li><strong>Feature Auditing:</strong> Removed "red_vehicle" (no predictive value per correlation analysis, avoids bias perception)</li>
        <li><strong>Fairness Testing:</strong> Verified no disparate impact on protected classes (gender, age groups)</li>
        <li><strong>Explainability:</strong> SHAP values provided to underwriters for manual review of borderline cases</li>
      </ul>

      <h3>Key Technical Achievements</h3>

      <ul>
        <li>Demonstrated dual-model approach (classification + regression) for expected value estimation in insurance domain</li>
        <li>Established threshold optimization protocol that prioritizes business objectives (recall) over traditional ML metrics (accuracy)</li>
        <li>Validated that SGD with log-transform outperforms tree methods for heavy-tailed financial distributions</li>
        <li>Built reproducible sklearn pipeline with custom transformers ensuring train/inference consistency, suitable for production after validation testing.</li>
        <li>Achieved 47% loss concentration in top decile, proving model can identify high-risk segments for actuarial pricing</li>
      </ul>

      <h3>Future Enhancements</h3>

      <ol>
        <li><strong>Telematics Integration:</strong> Incorporate real-time driving behavior (hard braking, speeding) from IoT devices</li>
        <li><strong>Geospatial Features:</strong> Accident hotspot density, weather patterns by zip code</li>
        <li><strong>Temporal Modeling:</strong> Account for claim seasonality (winter = more accidents)</li>
        <li><strong>Multi-Task Learning:</strong> Joint model predicting claim occurrence + severity simultaneously</li>
      </ol>
    </section>

  </main>

  <script>
    const sections = document.querySelectorAll('section');
    
    const observerOptions = {
      root: null,
      rootMargin: '0px',
      threshold: 0.15
    };
    
    const observer = new IntersectionObserver((entries) => {
      entries.forEach(entry => {
        if (entry.isIntersecting) {
          entry.target.classList.add('visible');
        }
      });
    }, observerOptions);
    
    sections.forEach(section => {
      observer.observe(section);
    });

    const navLinks = document.querySelectorAll('.sidebar-nav a');
    
    window.addEventListener('scroll', () => {
      let current = '';
      sections.forEach(section => {
        const sectionTop = section.offsetTop;
        if (scrollY >= (sectionTop - 200)) {
          current = section.getAttribute('id');
        }
      });

      navLinks.forEach(link => {
        link.classList.remove('active');
        if (link.getAttribute('href') === `#${current}`) {
          link.classList.add('active');
        }
      });
    });

    navLinks.forEach(link => {
      link.addEventListener('click', (e) => {
        e.preventDefault();
        const targetId = link.getAttribute('href');
        const targetSection = document.querySelector(targetId);
        window.scrollTo({
          top: targetSection.offsetTop - 40,
          behavior: 'smooth'
        });
      });
    });
  </script>

</body>
</html>